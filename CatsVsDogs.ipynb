{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnprr/CatsVsDogs/blob/main/CatsVsDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data and disc"
      ],
      "metadata": {
        "id": "4XrF6rSKaAbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_PgcaMQuBFl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "CWhXKX-EE9Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzom6GYU4_KF"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Programowanie/CatsVsDogs/KaggleToken/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NofgTy5T6Jw6"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCj970OW613c"
      },
      "outputs": [],
      "source": [
        "!unzip -q dogs-vs-cats-redux-kernels-edition.zip\n",
        "\n",
        "!unzip -q train.zip\n",
        "\n",
        "!rm test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3NZYUfn7lwL"
      },
      "outputs": [],
      "source": [
        "N_PER_SAMPLE = 1000\n",
        "path_cats = glob.glob(\"train/cat.*.jpg\")[: N_PER_SAMPLE]\n",
        "path_dogs = glob.glob(\"train/dog.*.jpg\")[: N_PER_SAMPLE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7XwexqV8tHG"
      },
      "outputs": [],
      "source": [
        "# #test images\n",
        "\n",
        "# import cv2\n",
        "# cat = cv2.imread(path_cats[1])\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# for i in range(20):\n",
        "#   cat = cv2.imread(path_cats[i])\n",
        "#   cv2_imshow(cat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T71Zeeak-cJK"
      },
      "outputs": [],
      "source": [
        "# Image statistics collection, calculation of average height and width.\n",
        "\n",
        "heights = []\n",
        "widths = []\n",
        "\n",
        "for path in path_cats + path_dogs:\n",
        "    # load img\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    # image size\n",
        "    height, width, channels = img.shape\n",
        "    heights.append(height)\n",
        "    widths.append(width)\n",
        "\n",
        "IMG_HEIGHT = int(np.round(np.mean(heights)))\n",
        "IMG_WIDTH = int(np.round(np.mean(widths)))\n",
        "\n",
        "print(IMG_HEIGHT, IMG_WIDTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Generator"
      ],
      "metadata": {
        "id": "x8x47k5kZX5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "!ls train/cats | wc -l\n",
        "!ls train/dogs | wc -l"
      ],
      "metadata": {
        "id": "m_CyeDggbW2M",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manage files\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# path\n",
        "train_folder = \"./train\"\n",
        "\n",
        "# Create subfolders for cats and dogs if they don't exist\n",
        "os.makedirs(os.path.join(train_folder, \"cats\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_folder, \"dogs\"), exist_ok=True)\n",
        "\n",
        "# Iterate through all files in the \"train\" folder\n",
        "for filename in os.listdir(train_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions if needed\n",
        "        file_path = os.path.join(train_folder, filename)\n",
        "\n",
        "        # Move cat images to the \"cats\" subfolder\n",
        "        if \"cat\" in filename.lower():\n",
        "            shutil.move(file_path, os.path.join(train_folder, \"cats\"))\n",
        "\n",
        "        # Move dog images to the \"dogs\" subfolder\n",
        "        if \"dog\" in filename.lower():\n",
        "            shutil.move(file_path, os.path.join(train_folder, \"dogs\"))"
      ],
      "metadata": {
        "id": "BL_xHJ4UFxn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take 2500 images for test\n",
        "\n",
        "# path\n",
        "test_folder = \"./test\"\n",
        "\n",
        "# Create subfolders for cats and dogs if they don't exist\n",
        "os.makedirs(os.path.join(test_folder, \"cats\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_folder, \"dogs\"), exist_ok=True)\n",
        "\n",
        "# Iterate through all files in the \"train\" folder\n",
        "for subdir in os.listdir(train_folder):\n",
        "    for filename in os.listdir(os.path.join(train_folder, subdir)):\n",
        "      if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Adjust file extensions if needed\n",
        "          if filename.split('.')[1] in [str(i) for i in range(10000, 12500)]:\n",
        "            file_path = os.path.join(train_folder, subdir, filename)\n",
        "            # Move cat images to the \"cats\" subfolder\n",
        "            if \"cat\" in filename.lower():\n",
        "                out_path = os.path.join(test_folder, 'cats', filename)\n",
        "                shutil.move(file_path, out_path)\n",
        "            # Move dog images to the \"dogs\" subfolder\n",
        "            if \"dog\" in filename.lower():\n",
        "                out_path = os.path.join(test_folder, 'dogs', filename)\n",
        "                shutil.move(file_path, out_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "itkatxpLZb6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls test/cats | wc -l\n",
        "!ls test/dogs | wc -l\n",
        "!ls train/cats | wc -l\n",
        "!ls train/dogs | wc -l"
      ],
      "metadata": {
        "id": "f6OCn7lPbqLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "def pf(image):\n",
        "  image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_HEIGHT) # Resize and pad images to ensure consistent dimensions\n",
        "  return image\n",
        "\n",
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=pf,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "#train dataset\n",
        "BATCH_SIZE = 64\n",
        "train_ds = img_gen.flow_from_directory(\n",
        "    \"./train\",\n",
        "    target_size=[IMG_WIDTH, IMG_HEIGHT],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    class_mode='binary', # Change class_mode to binary\n",
        "    color_mode='grayscale',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "#val dataset\n",
        "val_ds = img_gen.flow_from_directory(\n",
        "    \"./train\",\n",
        "    target_size=[IMG_WIDTH, IMG_HEIGHT],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    class_mode='binary', # Change class_mode to binary\n",
        "    color_mode='grayscale',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "id": "RbeJTsf1YWcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "mHknhAhDa35h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqykZkKfGS5d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# build model by using input\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 1)),  # input shape\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "#model 2\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=50, batch_size=1024, callbacks=[early])  # pobawić się batch size żeby było szybciej\n",
        "# history = model.fit(train_ds, validation_data=val_ds, epochs=10, batch_size=2048)  # pobawić się batch size żeby było szybciej"
      ],
      "metadata": {
        "id": "w1kMZXQoGYJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "MO4peOm5jQMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training history data\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create the accuracy plot\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Create the loss plot\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lLFFgvFFjHbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model and history\n",
        "import pickle\n",
        "\n",
        "model.save('/content/drive/MyDrive/Programowanie/CatsVsDogs/Modele/cat_dog_classifier1_25e.keras')\n",
        "with open('/content/drive/MyDrive/Programowanie/CatsVsDogs/Modele/cat_dog_classifier1_25e_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "metadata": {
        "id": "HHEwbmhXPN3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "YI66LXeTjNkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pf(image):\n",
        "  image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_HEIGHT) # Resize and pad images to ensure consistent dimensions\n",
        "  return image\n",
        "\n",
        "img_gen_test = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=pf,\n",
        ")\n",
        "\n",
        "#train dataset\n",
        "BATCH_SIZE = 64\n",
        "test_ds = img_gen_test.flow_from_directory(\n",
        "    \"./test\",\n",
        "    target_size=[IMG_WIDTH, IMG_HEIGHT],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    class_mode='binary', # Change class_mode to binary\n",
        "    color_mode='grayscale',\n",
        ")\n"
      ],
      "metadata": {
        "id": "82zQ0yAvXi2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test model\n",
        "results = model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
      ],
      "metadata": {
        "id": "-c0cD-BT1t-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1xViqGMuzDMr4-ScBHWqGYZu7Qz4so2bN",
      "authorship_tag": "ABX9TyOwEiTq9EE68vNqXQCTADu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}